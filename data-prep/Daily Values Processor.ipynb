{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and tidy up Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr = pd.read_csv(\"../raw-data/weather_history.csv\", low_memory=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr = wr.dropna(how='all', axis=1)\n",
    "wr = wr.drop('WW', axis=1)\n",
    "wr = wr.rename(columns={ wr.columns[0]: \"Time\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr = wr.rename(columns={'T':'Temp','U':'Rel_Humidity','DD':'Wind_Dir',\n",
    "                        'Tn':'Min_Temp','Tx':'Max_Temp','Td':'Dew_Temp',\n",
    "                        'RRR':'Rain','tR':'Rain_Time','Tg':'Night_Soil_Temp'})\n",
    "wr = wr.drop(['Dew_Temp','Night_Soil_Temp','Min_Temp','Max_Temp','Wind_Dir'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr['Rain'].replace('No precipitation',0, inplace=True)\n",
    "wr['Rain'] = pd.to_numeric(wr['Rain'])\n",
    "wr['Hourly_Rain'] = wr['Rain'] / wr['Rain_Time']\n",
    "wr = wr.drop(['Rain','Rain_Time'], axis = 1) # unclear why Rain_Time is sometimes 6 and sometimes 12\n",
    "wr['Time'] = pd.to_datetime(wr['Time'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr['Hour'] = wr['Time'].dt.hour\n",
    "wr['Date'] = wr['Time'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate weather by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrd = wr.groupby('Date').mean().reset_index()\n",
    "wrd = wrd.drop('Hour', axis=1)\n",
    "wrd['Date'] = pd.to_datetime(wrd['Date'])\n",
    "wrd['Date'] = wrd['Date'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Daily Cycle Hire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = pd.read_csv(\"../raw-data/daily-hires.csv\")\n",
    "dh['Date'] = pd.to_datetime(dh['Date'], dayfirst=True).dt.date\n",
    "dh['Hires']=dh['Hires'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import strike data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "strikes = pd.read_csv('../raw-data/tube-strikes.csv')\n",
    "strikes['Strike_Evening'] = pd.to_datetime(strikes['Strike_Evening'], dayfirst=True)\n",
    "strikes['Strike_Daytime'] = pd.to_datetime(strikes['Strike_Daytime'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import bank holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = pd.read_csv('../raw-data/bank-holidays.csv')\n",
    "bank['Date'] = pd.to_datetime(bank['Date'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import major London cycle accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyc = pd.read_csv('../raw-data/cycle-deaths-injuries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "death = cyc[cyc['Type']=='death']\n",
    "death = list(death['Date'])\n",
    "inj = cyc[cyc['Type']=='injury']\n",
    "inj = list(inj['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Import network size data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nw = pd.read_csv(\"../raw-data/hire-bike-volumes.csv\")\n",
    "\n",
    "nw = nw.rename(columns={'Stations':'Dock_Points'})\n",
    "nw['Date'] = pd.to_datetime(nw['Date'], dayfirst=True).dt.date\n",
    "\n",
    "#impute missing values using last known or estimated value\n",
    "nw = nw.fillna(method='ffill')\n",
    "nw =nw.replace({'Registration': {'Yes': True, 'No': False},\n",
    "               'Weekly_Fee':{'y': True, 'n': False}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe of previous and future dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [d for d in pd.date_range('20100730','20201231')] # until end of 2020\n",
    "dates = pd.DataFrame(dates, columns=['Date'])\n",
    "dates['Date'] = pd.to_datetime(dates['Date']).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Daily Cycle Hire, Aggregated Daily Weather, and Network Size data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = dates.merge(dh, how='left', on='Date')\n",
    "daily = daily.merge(wrd, how='left', on='Date')\n",
    "daily = daily.merge(nw, how='left', on='Date')\n",
    "daily['Date'] = pd.to_datetime(daily['Date'])\n",
    "daily = daily.sort_values(by=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_cols = ['Bicycles','Dock_Points','Registration','Sponsor','Fee','Weekly_Fee','Mobike','Ofo','Obike','Urbo']\n",
    "daily[fill_cols] = daily[fill_cols].fillna(method='ffill')\n",
    "daily['Comp_bikes'] = daily[['Mobike','Ofo','Obike','Urbo']].sum(axis=1)\n",
    "daily['hpb'] = daily['Hires'] / daily['Bicycles'] #hires per bike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add strikes, bank holidays and accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily['Strike_Evening'] = daily['Date'].isin(strikes['Strike_Evening'])\n",
    "daily['Strike_Daytime'] = daily['Date'].isin(strikes['Strike_Daytime'])\n",
    "daily['Strike'] = (daily['Strike_Evening']) | (daily['Strike_Daytime'])\n",
    "daily['Bank_Hol'] = daily['Date'].isin(bank['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily['Death'] = daily['Date'].isin(death)\n",
    "daily['Inj'] = daily['Date'].isin(inj)\n",
    "daily['KSI'] = (daily['Death']) | (daily['Inj'])\n",
    "daily['KSI_day_before'] = daily['KSI'].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily['Month'] = daily['Date'].dt.month\n",
    "daily['Year'] = daily['Date'].dt.year\n",
    "daily['Day_of_Week'] = daily['Date'].dt.weekday\n",
    "daily['Weekend'] = daily['Day_of_Week'] > 4\n",
    "daily['Day_of_Year'] = daily['Date'].dt.dayofyear\n",
    "\n",
    "daily['Wkend_or_Hol'] = (daily['Bank_Hol']) | (daily['Weekend'])\n",
    "daily['Date'] = daily['Date'].dt.date\n",
    "daily = daily.sort_values(by=\"Date\")\n",
    "days=[\"Mon\",\"Tues\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "\n",
    "\n",
    "def day(number):\n",
    "    return days[number]\n",
    "\n",
    "daily['Day'] = daily['Day_of_Week'].apply(day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and add daylight hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "light = pd.read_csv('../raw-data/civil-twilight-2017.csv')\n",
    "\n",
    "light['Dark'] = pd.to_datetime(light['Dark'],format= '%H:%M')\n",
    "light['Light'] = pd.to_datetime(light['Light'],format= '%H:%M')\n",
    "\n",
    "light['Hours_Light'] = (light['Dark'] - light['Light'])\n",
    "light['Dark'] = light['Dark'].dt.time\n",
    "light['Light'] = light['Light'].dt.time\n",
    "\n",
    "light['Hours_Light'] = (light['Hours_Light'].dt.seconds) / 3600\n",
    "\n",
    "light['Day_of_Year'] = pd.to_datetime(light['Date']).dt.dayofyear\n",
    "light = light.drop(['Date'], axis=1)\n",
    "\n",
    "daily = daily.merge(light, how='left', on='Day_of_Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.to_csv('../data/daily.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
